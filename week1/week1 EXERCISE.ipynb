{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an assistant that will answer technical questions for programming. When giving try to give in an explanation and and example. \\\n",
    "        Explaining the parts of the example if any. Respond in markdown format. If in your response you see the word 'dict', 'and', or 'books', I want you to underline the word. \\\n",
    "        At the very end of the response, create a witty joke about the number of rockets you found!\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e69e755-b464-44f1-8852-85cc0448336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code snippet is using the `yield from` syntax in conjunction with a set comprehension to produce a generator.\n",
       "\n",
       "### Explanation\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   \n",
       "   - This part of the code creates a set by iterating over each `book` in the `books` collection.\n",
       "   - For each `book`, it uses `.get(\"author\")` to retrieve the value associated with the key `\"author\"`.\n",
       "   - The `if book.get(\"author\")` part ensures that only books that have an author (i.e., where `book.get(\"author\")` returns a truthy value) are considered for the set. If a book does not have an author, it will be excluded from the set.\n",
       "\n",
       "2. **`yield from`**:\n",
       "   - The `yield from` statement is used in a generator function to yield values from another iterable or generator. In this case, it allows the generator to produce each author in the set one by one.\n",
       "   - So, the entire line allows a generator to yield each unique author from the collection of `books`.\n",
       "\n",
       "### Example\n",
       "\n",
       "Here‚Äôs a more complete example:\n",
       "\n",
       "python\n",
       "def get_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Example usage\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\"},\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n",
       "]\n",
       "\n",
       "for author in get_authors(books):\n",
       "    print(author)\n",
       "\n",
       "\n",
       "### Breakdown of the Example:\n",
       "\n",
       "- **Defining a Function**: `get_authors(books)` is a generator function that will yield authors from the provided list of `books`.\n",
       "- **Input List**: The `books` list includes dictionaries representing books, with most having an `\"author\"` key.\n",
       "- **Using the Function**: When we loop through the authors produced by `get_authors(books)`, it will print unique authors:\n",
       "  \n",
       "  Author A\n",
       "  Author B\n",
       "  \n",
       "  Notice how it yields `Author A` only once, even though two books share that author.\n",
       "\n",
       "In summary, this code efficiently compiles a list of unique authors from a potentially large collection of books, while also ensuring that any entries without an author are excluded.\n",
       "\n",
       "And as for the rockets, I found a lot of them, probably enough to launch a ‚Äúspace book‚Äù club! üöÄ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def stream_response(stream):\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "def call_open_ai_stream(prompt):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=prompt,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    stream_response(stream)\n",
    "\n",
    "\n",
    "call_open_ai_stream(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Unpacking a Nested Generator**\n",
       "=====================================\n",
       "\n",
       "The provided code snippet is using generator expression and `yield from` to extract the authors of books from a list. Here's a breakdown:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "*   `{...}` : This syntax creates an empty dictionary comprehension, which might seem unusual at first. However, it serves a purpose similar to `dict comprehension`.\n",
       "\n",
       "However there is not enough information about the code structure and libraries used. So Below I'll give 2 possible structure.\n",
       "\n",
       "### Structure 1\n",
       "\n",
       "python\n",
       "import collections.abc\n",
       "\n",
       "def get_books(books):\n",
       "    for book in books:\n",
       "        yield from {\n",
       "            key: value \n",
       "            for key, value in book.items()\n",
       "            if key != 'author' or (key == 'author' and value)\n",
       "        }\n",
       "\n",
       "def find_authors():\n",
       "    authors = {}\n",
       "    for book in books:\n",
       "        author = next(book.values())\n",
       "        if not author:\n",
       "            continue\n",
       "        if author not in authors.values():\n",
       "            yield author \n",
       "\n",
       "# Example usage\n",
       "books = [\n",
       "    {\"title\": \"Book1\", \"author\": \"John\"},\n",
       "    {\"title\": \"Book2\", \"author\": \"\"},\n",
       "    {\"title\": \"-3-Book3\", \"author\": \"Alessandro\"}\n",
       "]\n",
       "books = [book for book in books if book] # drop the empty books\n",
       "\n",
       "authors = set(list(find_authors()))\n",
       "print(authors) \n",
       "\n",
       "In this code `get_books` is function that yield each line of a JSON. We are also filtering out some lines (as requested).\n",
       "\n",
       "python\n",
       "    def find_authors():\n",
       "        authors = {}\n",
       "        for book in books:\n",
       "            author = next(book.values())\n",
       "            if not author:\n",
       "                continue\n",
       "            if author not in authors.values():\n",
       "                yield author \n",
       "\n",
       "`find_authors()` function filters duplicate value and also skipping on None."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def call_ollama_stream(prompt):\n",
    "    ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=prompt,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    stream_response(stream)\n",
    "\n",
    "call_ollama_stream(messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620dace-37ac-4cd6-83eb-20fdb73cae94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
